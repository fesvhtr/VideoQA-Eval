# VideoQA-Eval
This repo contains a comprehensive metric toolset for evaluation NLG, videoQA, etc. tasks. We also offer a reading list of related papers and repositories.

## Our MMEval Metric
MMEval is a novel LLM-based metric designed for Video Question Answering, which can utilize multimodal information to evaluate answers.
You can find more in our new CVPR2024 paper [CUVA]() and [github repo](https://github.com/fesvhtr/CUVA).
## Installation

## Reading List & Acknowledgements
Thank the following repositories and authors for their contributions to VideoQA Metrics, Their work has been instrumental in enhancing our project and we are grateful for their efforts.
- **BLEU** (ACL2002) [paper](https://aclanthology.org/P02-1040.pdf)
- **ROUGE** (ACL2004) [paper](https://aclanthology.org/W04-1013.pdf)
- **METEOR** (ACL2005) [paper](https://aclanthology.org/W05-0909.pdf)
- **CIDEr** (CVPR2015) [paper](https://openaccess.thecvf.com/content_cvpr_2015/papers/Vedantam_CIDEr_Consensus-Based_Image_2015_CVPR_paper.pdf)
- **MoverScore** (EMNLP2019) [paper](https://arxiv.org/pdf/1909.02622) [repository](https://github.com/AIPHES/emnlp19-moverscore)
- **COMET** (EMNLP2020) [paper](https://aclanthology.org/2020.emnlp-main.213.pdf)
- **BLEURT** (ACL2020) [paper](https://aclanthology.org/2020.acl-main.704.pdf) [repository](https://github.com/google-research/bleurt)
- **UniEval** (EMNLP2022) [paper](https://aclanthology.org/2022.emnlp-main.131.pdf) [repository](https://github.com/maszhongming/UniEval)
- **FunQA** (2023) [paper](https://arxiv.org/pdf/2306.14899) [repository](https://github.com/Jingkang50/FunQA)
- **MMEval** (CVPR2024) [paper]() [repository](https://github.com/fesvhtr/CUVA)
