# VideoQA-Eval
A comprehensive metric toolset for evaluation NLG, videoQA, etc. tasks.

## Our MMEval Metric
MMEval is a novel LLM-based metric designed for Video Question Answering, which can utilize multimodal information to evaluate answers.
You can find more in our new CVPR2024 paper [CUVA]() and [github repo](https://github.com/fesvhtr/CUVA).
## Installation

## Acknowledgements
Thank the following repositories and authors for their contributions to VideoQA Metrics, Their work has been instrumental in enhancing our project and we are grateful for their efforts.
- **BLEU**
- **ROUGE**
- **BLEURT** <[paper]()> <[repository]()> by <author_name>
- **MoverScore** (EMNLP2019) <[paper]()> <[repository]()> by <author_name>
- **UniEval** <[paper]()> <[repository]()> by <author_name>
